{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Preditivo para descobrir qual vai ser o próximo hit do Sportify - Marcelo Rossignolli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa as bibliotecas permitidas \n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Limpeza e Tratamento de Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define o dataset de treino e teste\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Verificação de valores nulos:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Antes de iniciar o pré-processamento, verifiquei a existência de valores nulos nas colunas do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_unique_id      0\n",
      "track_id             0\n",
      "artists              0\n",
      "album_name           0\n",
      "track_name           0\n",
      "duration_ms          0\n",
      "explicit             0\n",
      "danceability         0\n",
      "energy               0\n",
      "key                  0\n",
      "loudness             0\n",
      "mode                 0\n",
      "speechiness          0\n",
      "acousticness         0\n",
      "instrumentalness     0\n",
      "liveness             0\n",
      "valence              0\n",
      "tempo                0\n",
      "time_signature       0\n",
      "track_genre          0\n",
      "popularity_target    0\n",
      "dtype: int64\n",
      "track_unique_id     0\n",
      "track_id            0\n",
      "artists             1\n",
      "album_name          1\n",
      "track_name          1\n",
      "duration_ms         0\n",
      "explicit            0\n",
      "danceability        0\n",
      "energy              0\n",
      "key                 0\n",
      "loudness            0\n",
      "mode                0\n",
      "speechiness         0\n",
      "acousticness        0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "valence             0\n",
      "tempo               0\n",
      "time_signature      0\n",
      "track_genre         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tratamento de valores nulos:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Para colunas numéricas com valores nulos: substituí valores ausentes pela mediana de cada coluna, uma vez que a mediana é menos sensível a outliers.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Para colunas categóricas: Os valores nulos foram substituídos por 'unknown', garantindo que esses dados possam ser codificados sem perda de informação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituindo valores nulos nas colunas numéricas\n",
    "numeric_columns = df_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "df_train[numeric_columns] = df_train[numeric_columns].fillna(df_train[numeric_columns].median())\n",
    "\n",
    "# Substituindo valores nulos nas colunas categóricas\n",
    "categorical_columns = df_train.select_dtypes(include=['object', 'bool']).columns\n",
    "df_train[categorical_columns] = df_train[categorical_columns].fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tratamento de outliers:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Os outliers foram detectados e tratados usando o método de IQR, limitando os valores ao intervalo entre o percentil 1 e 99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento de outliers\n",
    "Q1 = df_train[numeric_columns].quantile(0.25)\n",
    "Q3 = df_train[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df_train = df_train[~((df_train[numeric_columns] < (Q1 - 1.5 * IQR)) | (df_train[numeric_columns] > (Q3 + 1.5 * IQR))).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Codificação de Variáveis Categóricas\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Utilizei OneHotEncoder para transformar as variáveis categóricas em formato numérico adequado para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Aplicando o OneHotEncoder nas colunas categóricas\n",
    "categorical_columns = ['track_id', 'artists', 'album_name', 'track_name', 'explicit', 'track_genre']\n",
    "numeric_columns = ['duration_ms', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "                   'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n",
    "\n",
    "# Definindo o pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploração e Visualização dos Dados\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;A exploração dos dados fpoi feita utilizando métodos Pandas como describe() e value_counts()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Distribuição da variável alvo (popularity_target):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity_target\n",
      "1    23321\n",
      "0    20771\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distribuição da variável alvo\n",
    "print(df_train['popularity_target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Estatísticas descritivas das variáveis numéricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       track_unique_id    duration_ms  danceability        energy  \\\n",
      "count     44092.000000   44092.000000  44092.000000  44092.000000   \n",
      "mean      58521.654813  216280.139663      0.593321      0.671343   \n",
      "std       32154.042899   55803.002597      0.147202      0.212995   \n",
      "min           0.000000   44040.000000      0.098900      0.009940   \n",
      "25%       31439.750000  178373.000000      0.495000      0.522000   \n",
      "50%       61214.500000  211920.000000      0.599000      0.704000   \n",
      "75%       86391.250000  249643.250000      0.701000      0.849000   \n",
      "max      113998.000000  391895.000000      0.984000      1.000000   \n",
      "\n",
      "                key      loudness          mode   speechiness  acousticness  \\\n",
      "count  44092.000000  44092.000000  44092.000000  44092.000000  44092.000000   \n",
      "mean       5.301143     -6.912627      0.658963      0.055647      0.276512   \n",
      "std        3.560273      3.087871      0.474063      0.029563      0.294876   \n",
      "min        0.000000    -17.514000      0.000000      0.022100      0.000000   \n",
      "25%        2.000000     -8.628000      0.000000      0.033900      0.020400   \n",
      "50%        5.000000     -6.318000      1.000000      0.045000      0.150000   \n",
      "75%        8.000000     -4.641000      1.000000      0.067800      0.497000   \n",
      "max       11.000000      0.605000      1.000000      0.157000      0.996000   \n",
      "\n",
      "       instrumentalness      liveness       valence         tempo  \\\n",
      "count      44092.000000  44092.000000  44092.000000  44092.000000   \n",
      "mean           0.005143      0.172220      0.530376    121.937965   \n",
      "std            0.017444      0.107424      0.242898     27.897249   \n",
      "min            0.000000      0.009250      0.000010     45.664000   \n",
      "25%            0.000000      0.095600      0.334000     99.986000   \n",
      "50%            0.000004      0.128000      0.528000    121.774000   \n",
      "75%            0.000410      0.234000      0.726000    139.990000   \n",
      "max            0.126000      0.535000      0.994000    201.500000   \n",
      "\n",
      "       time_signature  popularity_target  \n",
      "count         44092.0       44092.000000  \n",
      "mean              4.0           0.528917  \n",
      "std               0.0           0.499169  \n",
      "min               4.0           0.000000  \n",
      "25%               4.0           0.000000  \n",
      "50%               4.0           1.000000  \n",
      "75%               4.0           1.000000  \n",
      "max               4.0           1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Estatísticas descritivas\n",
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Formulação de Hipóteses \n",
    "\n",
    "- Hipótese 1: Músicas com maior \"danceability\" tendem a ser mais populares.\n",
    "\n",
    "- Hipótese 2: Músicas explicitamente marcadas como \"explicit=True\" têm mais chances de ser populares.\n",
    "\n",
    "- Hipótese 3: Músicas com valores mais altos de \"energy\" são mais propensas a se tornarem populares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Seleção de Features (até 1,0 pt)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Com base nas hipóteses e na análise exploratória, as seguintes features foram escolhidas para o modelo:\n",
    "\n",
    "- Numéricas: \"danceability\", \"energy\", \"tempo\", \"loudness\", \"acousticness\".\n",
    "\n",
    "- Categóricas: \"explicit\", \"track_genre\", \"album_name\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Construção e Avaliação do Modelo \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Utilizamos o RandomForestClassifier para a previsão da popularidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de validação: 0.8567864837283139\n"
     ]
    }
   ],
   "source": [
    "# Verificando se a coluna 'track_id' realmente existe e ajustando conforme necessário\n",
    "categorical_columns = ['artists', 'album_name', 'track_name', 'explicit', 'track_genre']\n",
    "numeric_columns = ['duration_ms', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "                   'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n",
    "\n",
    "# Se 'track_id' não existe, remova-a\n",
    "X = df_train.drop(columns=['popularity_target', 'track_unique_id'])  # Remova apenas as colunas que realmente existem\n",
    "y = df_train['popularity_target']\n",
    "\n",
    "# Dividindo os dados em treino e validação\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Aplicando o pré-processamento e treinando o modelo\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Preprocessamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Aplicando o pré-processamento\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_val = preprocessor.transform(X_val)\n",
    "\n",
    "# Treinando o modelo\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliando o modelo\n",
    "print(\"Acurácia no conjunto de validação:\", model.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Geração do Arquivo de Submissão\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Após realizar as previsões no conjunto de teste, geramos o arquivo CSV contendo o track_unique_id e a predição do popularity_target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Preservar a coluna 'track_unique_id' para o arquivo de submissão\n",
    "track_unique_id = df_test['track_unique_id'].copy()\n",
    "\n",
    "# Remover as colunas 'track_id' e 'track_unique_id' antes de passar os dados ao modelo\n",
    "df_test_features = df_test.drop(columns=['track_id', 'track_unique_id'], errors='ignore')\n",
    "\n",
    "# Fazendo previsões com o pipeline já treinado\n",
    "test_data_predictions = model_pipeline.predict(df_test_features)\n",
    "\n",
    "# Criando o DataFrame de submissão, usando a coluna 'track_unique_id' preservada\n",
    "submission = pd.DataFrame({\n",
    "    'track_unique_id': track_unique_id,\n",
    "    'popularity_target': test_data_predictions\n",
    "})\n",
    "\n",
    "# Salvando o resultado no arquivo CSV\n",
    "submission.to_csv('modelo.csv', index=False)\n",
    "\n",
    "print(\"Arquivo salvo com sucesso.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
